# Semana 3: Retrieval-Augmented Generation (RAG)

## ğŸ¯ Objetivo Geral
Dominar o conceito e implementaÃ§Ã£o prÃ¡tica de RAG (Retrieval-Augmented Generation), combinando busca semÃ¢ntica com geraÃ§Ã£o de texto para criar sistemas de Q&A inteligentes.

---

## ğŸ“… Cronograma DiÃ¡rio (7 dias)

### **Dia 1: Teoria e Arquitetura RAG**
**Tempo:** 30-45 min  
**Objetivo:** Entender completamente o conceito de RAG e sua arquitetura

**Atividades:**
- [ ] ğŸ“– Ler: [What is RAG?](https://blogs.nvidia.com/blog/2023/11/13/what-is-retrieval-augmented-generation/)
- [ ] ğŸ“– Ler: [RAG vs Fine Tuning](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [ ] ğŸ“ Desenhar diagrama da arquitetura RAG (Retrieval â†’ Augmentation â†’ Generation)
- [ ] ğŸ§  Listar 5 casos de uso onde RAG Ã© melhor que fine-tuning
- [ ] ğŸ“ Resumir vantagens e limitaÃ§Ãµes do RAG

**Resultado esperado:** CompreensÃ£o sÃ³lida do que Ã© RAG e quando usar

---

### **Dia 2: LangChain Fundamentals**
**Tempo:** 45-60 min  
**Objetivo:** Setup e primeiros passos com LangChain para RAG

**Atividades:**
- [ ] ğŸ“– Ler: [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- [ ] âš™ï¸ Instalar dependÃªncias: langchain, openai, chromadb
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_01_langchain_basico.py`: loader + splitter + embeddings
- [ ] ğŸ§ª Testar com documento de texto simples (PDF ou TXT)
- [ ] ğŸ“ Documentar cada componente: DocumentLoader, TextSplitter, VectorStore

**Resultado esperado:** Pipeline bÃ¡sico de ingesting de documentos funcionando

---

### **Dia 3: LlamaIndex Fundamentals**
**Tempo:** 45-60 min  
**Objetivo:** Comparar abordagem do LlamaIndex vs LangChain

**Atividades:**
- [ ] ğŸ“– Ler: [LlamaIndex Quickstart](https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html)
- [ ] âš™ï¸ Instalar llama-index
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_02_llamaindex_basico.py`: SimpleDirectoryReader + VectorStoreIndex
- [ ] ğŸ§ª Usar mesmo documento do dia anterior
- [ ] ğŸ“Š Comparar: facilidade de uso, velocidade, qualidade das respostas
- [ ] ğŸ“ Documentar diferenÃ§as entre LangChain e LlamaIndex

**Resultado esperado:** DomÃ­nio de dois principais frameworks para RAG

---

### **Dia 4: Chunking Strategies**
**Tempo:** 45-60 min  
**Objetivo:** Otimizar estratÃ©gias de divisÃ£o de texto para melhor retrieval

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_03_chunking_strategies.py`
- [ ] ğŸ§ª Testar diferentes abordagens:
  - Character splitting (tamanho fixo)
  - Recursive character splitting
  - Semantic chunking
  - Document-aware splitting
- [ ] ğŸ“Š Comparar qualidade das respostas para cada mÃ©todo
- [ ] ğŸ” Analisar: qual chunking funciona melhor para que tipo de documento?
- [ ] ğŸ“ Documentar melhores prÃ¡ticas de chunking

**Resultado esperado:** Expertise em otimizaÃ§Ã£o de chunking para diferentes cenÃ¡rios

---

### **Dia 5: Prompt Engineering para RAG**
**Tempo:** 45-60 min  
**Objetivo:** Melhorar qualidade das respostas atravÃ©s de prompt engineering

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_04_prompt_engineering.py`
- [ ] ğŸ§ª Testar diferentes templates de prompt:
  - Basic: "Answer based on context: {context}\nQuestion: {question}"
  - Detailed: InstruÃ§Ãµes especÃ­ficas sobre como responder
  - Chain-of-thought: Pedir para explicar raciocÃ­nio
  - Few-shot: Incluir exemplos
- [ ] ğŸ“Š Avaliar qualidade das respostas para cada template
- [ ] ğŸ” Identificar quando cada tipo de prompt funciona melhor
- [ ] ğŸ“ Criar biblioteca de prompts reutilizÃ¡veis

**Resultado esperado:** Biblioteca de prompts otimizados para diferentes casos de uso

---

### **Dia 6: AvaliaÃ§Ã£o e MÃ©tricas**
**Tempo:** 45-60 min  
**Objetivo:** Implementar mÃ©tricas para avaliar qualidade do sistema RAG

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_05_avaliacao.py`
- [ ] ğŸ“Š Implementar mÃ©tricas:
  - RelevÃ¢ncia dos documentos recuperados
  - Qualidade das respostas (BLEU, ROUGE se possÃ­vel)
  - Tempo de resposta
- [ ] ğŸ§ª Criar dataset de test com perguntas e respostas esperadas
- [ ] ğŸ“ˆ Comparar performance de diferentes configuraÃ§Ãµes
- [ ] ğŸ“ Dashboard simples para visualizar mÃ©tricas

**Resultado esperado:** Sistema de avaliaÃ§Ã£o automatizada do RAG

---

### **Dia 7: Mini-Projeto Final**
**Tempo:** 60-90 min  
**Objetivo:** Q&A system completo sobre documentos prÃ³prios

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `mini_projeto_qa_pessoal.py`
- [ ] ğŸ“š Dataset: Documentos pessoais (PDFs, artigos salvos, notas)
- [ ] ğŸ—ï¸ Pipeline completo: ingestÃ£o â†’ chunking â†’ embedding â†’ retrieval â†’ geraÃ§Ã£o
- [ ] ğŸ’» Interface: Streamlit ou gradio para interaÃ§Ã£o
- [ ] ğŸ§ª Testar com perguntas complexas sobre seus documentos
- [ ] ğŸ“Š Incluir mÃ©tricas de avaliaÃ§Ã£o em tempo real
- [ ] ğŸ“ README detalhado com arquitetura e resultados
- [ ] ğŸ‰ Demo funcionando + anÃ¡lise de limitaÃ§Ãµes

**Resultado esperado:** Sistema RAG completo e funcional para uso pessoal

---

## ğŸ“š Recursos de Estudo

### **Leituras Essenciais**
- [RAG com LlamaIndex](https://docs.llamaindex.ai/en/stable/getting_started/concepts.html)
- [RAG com LangChain](https://python.langchain.com/docs/use_cases/question_answering/)
- [Chunking Strategies](https://www.pinecone.io/learn/chunking-strategies/)

### **Leituras Complementares**
- [Advanced RAG Techniques](https://blog.langchain.dev/semi-structured-multi-modal-rag/)
- [RAG vs Fine-tuning](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1)
- [Evaluation of RAG Systems](https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/)

### **VÃ­deos Recomendados**
- [LangChain RAG from Scratch](https://www.youtube.com/watch?v=LhnCsygAvzY)
- [LlamaIndex in 5 Minutes](https://www.youtube.com/watch?v=hA1JPOy9KCc)

---

## ğŸ› ï¸ Setup TÃ©cnico

### **DependÃªncias**
```bash
# Adicionar ao requirements.txt
langchain==0.0.340
llama-index==0.9.13
openai==1.3.5
chromadb==0.4.18
tiktoken==0.5.1
pypdf==3.17.1
streamlit==1.28.2
gradio==4.7.1
sentence-transformers==2.2.2
faiss-cpu==1.7.4
```

### **Estrutura de Arquivos**
```
semana03-rag/
â”œâ”€â”€ notas.md                          # Este arquivo
â”œâ”€â”€ experimentos.md                   # Suas anotaÃ§Ãµes
â”œâ”€â”€ exemplos/
â”‚   â”œâ”€â”€ exemplo_01_langchain_basico.py
â”‚   â”œâ”€â”€ exemplo_02_llamaindex_basico.py
â”‚   â”œâ”€â”€ exemplo_03_chunking_strategies.py
â”‚   â”œâ”€â”€ exemplo_04_prompt_engineering.py
â”‚   â””â”€â”€ exemplo_05_avaliacao.py
â””â”€â”€ mini-projeto/
    â”œâ”€â”€ mini_projeto_qa_pessoal.py
    â”œâ”€â”€ interface_streamlit.py
    â”œâ”€â”€ documentos/                   # Seus documentos de teste
    â”œâ”€â”€ prompts_library.py
    â””â”€â”€ README.md
```

---

## âœ… Checklist de Aprendizado

### **Conceitos TeÃ³ricos**
- [ ] Consigo explicar RAG vs fine-tuning em 3 minutos
- [ ] Entendo os componentes: Retrieval, Augmentation, Generation
- [ ] Sei quando usar LangChain vs LlamaIndex
- [ ] ConheÃ§o diferentes estratÃ©gias de chunking

### **Habilidades PrÃ¡ticas**
- [ ] Implementei RAG com LangChain
- [ ] Implementei RAG com LlamaIndex
- [ ] Testei diferentes estratÃ©gias de chunking
- [ ] Criei prompts otimizados para RAG
- [ ] Implementei sistema de avaliaÃ§Ã£o

### **Projeto Final**
- [ ] Q&A system funcionando com documentos prÃ³prios
- [ ] Interface web para interaÃ§Ã£o
- [ ] MÃ©tricas de avaliaÃ§Ã£o implementadas
- [ ] DocumentaÃ§Ã£o completa

---

## ğŸ“ EspaÃ§o para AnotaÃ§Ãµes

### **ComparaÃ§Ã£o LangChain vs LlamaIndex**
- **LangChain:**
  - PrÃ³s:
  - Contras:
- **LlamaIndex:**
  - PrÃ³s:
  - Contras:

### **Melhores EstratÃ©gias de Chunking**
- Para documentos tÃ©cnicos:
- Para narrativas/livros:
- Para artigos acadÃªmicos:

### **Prompts que Funcionaram Bem**
- (Cole aqui os prompts que deram melhores resultados)

### **LimitaÃ§Ãµes Identificadas**
- (O que nÃ£o funcionou bem? Que problemas encontrou?)

### **Ideias para PrÃ³ximos Projetos**
- (InspiraÃ§Ãµes para projetos mais avanÃ§ados com RAG) 