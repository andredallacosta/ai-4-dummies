# Semana 6: Fine Tuning e LoRA

## ğŸ¯ Objetivo Geral
Dominar tÃ©cnicas de fine-tuning e LoRA (Low-Rank Adaptation) para adaptar modelos prÃ©-treinados Ã s necessidades especÃ­ficas, incluindo quantizaÃ§Ã£o e otimizaÃ§Ã£o de modelos.

---

## ğŸ“… Cronograma DiÃ¡rio (7 dias)

### **Dia 1: Teoria do Fine-Tuning**
**Tempo:** 30-45 min  
**Objetivo:** Entender conceitos fundamentais de fine-tuning vs outras abordagens

**Atividades:**
- [ ] ğŸ“– Ler: [Fine-tuning vs RAG vs Prompt Engineering](https://blog.langchain.dev/fine-tuning-vs-retrieval-augmented-generation/)
- [ ] ğŸ“– Ler: [When to Fine-tune](https://platform.openai.com/docs/guides/fine-tuning/when-to-use-fine-tuning)
- [ ] ğŸ“ Resumir: Quando usar fine-tuning, RAG ou prompt engineering
- [ ] ğŸ§  Listar 5 cenÃ¡rios ideais para fine-tuning
- [ ] ğŸ“ Mapear custos e benefÃ­cios de cada abordagem

**Resultado esperado:** CompreensÃ£o clara de quando aplicar fine-tuning

---

### **Dia 2: IntroduÃ§Ã£o ao LoRA**
**Tempo:** 45-60 min  
**Objetivo:** Entender a tÃ©cnica LoRA e suas vantagens

**Atividades:**
- [ ] ğŸ“– Ler: [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [ ] ğŸ“– Ler: [LoRA Explained Simply](https://blog.paperspace.com/lora-explained/)
- [ ] ğŸ“ Desenhar diagrama da arquitetura LoRA
- [ ] ğŸ§  Entender matemÃ¡tica: A + BA onde A,B sÃ£o matrizes de rank baixo
- [ ] ğŸ“ Comparar LoRA vs full fine-tuning: memÃ³ria, tempo, qualidade

**Resultado esperado:** DomÃ­nio conceitual da tÃ©cnica LoRA

---

### **Dia 3: Setup e Primeiro Fine-Tuning**
**Tempo:** 45-60 min  
**Objetivo:** Configurar ambiente e executar primeiro fine-tuning

**Atividades:**
- [ ] âš™ï¸ Setup ambiente: transformers, peft, bitsandbytes
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_01_fine_tuning_basico.py`
- [ ] ğŸ§ª Fine-tuning simples com modelo pequeno (GPT-2 ou DistilGPT-2)
- [ ] ğŸ“Š Comparar modelo original vs fine-tuned
- [ ] ğŸ“ Documentar processo e resultados

**Resultado esperado:** Primeiro fine-tuning funcionando

---

### **Dia 4: LoRA com HuggingFace PEFT**
**Tempo:** 45-60 min  
**Objetivo:** Implementar LoRA usando biblioteca PEFT

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_02_lora_peft.py`
- [ ] ğŸ§ª Aplicar LoRA em modelo maior (Llama 2 7B ou similar)
- [ ] âš™ï¸ Configurar hiperparÃ¢metros: rank, alpha, dropout
- [ ] ğŸ“Š Comparar uso de memÃ³ria: full vs LoRA
- [ ] ğŸ“ Documentar configuraÃ§Ãµes Ã³timas encontradas

**Resultado esperado:** LoRA funcionando com modelo de produÃ§Ã£o

---

### **Dia 5: QuantizaÃ§Ã£o e OtimizaÃ§Ã£o**
**Tempo:** 45-60 min  
**Objetivo:** Aplicar tÃ©cnicas de quantizaÃ§Ã£o para otimizar modelos

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_03_quantizacao.py`
- [ ] ğŸ§ª Testar diferentes tÃ©cnicas:
  - 8-bit quantization
  - 4-bit quantization (QLoRA)
  - GPTQ quantization
- [ ] ğŸ“Š Comparar: velocidade, memÃ³ria, qualidade
- [ ] ğŸ” Identificar trade-offs para cada tÃ©cnica
- [ ] ğŸ“ Guia de quando usar cada tipo de quantizaÃ§Ã£o

**Resultado esperado:** Expertise em otimizaÃ§Ã£o de modelos

---

### **Dia 6: Dataset Preparation e AvaliaÃ§Ã£o**
**Tempo:** 45-60 min  
**Objetivo:** Preparar datasets prÃ³prios e avaliar qualidade do fine-tuning

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `exemplo_04_dataset_preparation.py`
- [ ] ğŸ“š Preparar dataset personalizado (chat, classificaÃ§Ã£o, ou geraÃ§Ã£o)
- [ ] ğŸ§ª Implementar mÃ©tricas de avaliaÃ§Ã£o:
  - Perplexity
  - BLEU/ROUGE (se aplicÃ¡vel)
  - Accuracy (para classificaÃ§Ã£o)
- [ ] ğŸ“Š Comparar performance antes/depois do fine-tuning
- [ ] ğŸ“ Documentar melhores prÃ¡ticas para preparaÃ§Ã£o de dados

**Resultado esperado:** Pipeline completo de preparaÃ§Ã£o e avaliaÃ§Ã£o

---

### **Dia 7: Mini-Projeto Final**
**Tempo:** 60-90 min  
**Objetivo:** Fine-tuning completo para caso de uso especÃ­fico

**Atividades:**
- [ ] ğŸ‘¨â€ğŸ’» Criar `mini_projeto_fine_tuning_especializado/`
- [ ] ğŸ¯ Escolher caso de uso especÃ­fico:
  - Chatbot especializado em domÃ­nio
  - Gerador de cÃ³digo
  - Classificador de texto
- [ ] ğŸ—ï¸ Pipeline completo:
  - Coleta/preparaÃ§Ã£o de dados
  - Fine-tuning com LoRA
  - QuantizaÃ§Ã£o para deployment
  - Interface de teste
- [ ] ğŸ“Š Dashboard de mÃ©tricas e comparaÃ§Ãµes
- [ ] ğŸ“ README detalhado com resultados e anÃ¡lises
- [ ] ğŸ‰ Demo funcionando + anÃ¡lise de melhorias

**Resultado esperado:** Modelo fine-tuned pronto para produÃ§Ã£o

---

## ğŸ“š Recursos de Estudo

### **Leituras Essenciais**
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [HuggingFace PEFT](https://github.com/huggingface/peft)
- [Fine-tuning Best Practices](https://blog.paperspace.com/fine-tuning-transformers/)

### **Leituras Complementares**
- [QLoRA Paper](https://arxiv.org/abs/2305.14314)
- [AdaLoRA: Adaptive Budget Allocation](https://arxiv.org/abs/2303.10512)
- [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)

### **Tutoriais PrÃ¡ticos**
- [Fine-tuning Llama 2 with LoRA](https://blog.paperspace.com/fine-tune-llama-2-with-lora/)
- [PEFT Documentation](https://huggingface.co/docs/peft/index)
- [Quantization Guide](https://huggingface.co/docs/transformers/quantization)

---

## ğŸ› ï¸ Setup TÃ©cnico

### **DependÃªncias**
```bash
# Adicionar ao requirements.txt
transformers==4.36.0
peft==0.7.1
bitsandbytes==0.41.3
datasets==2.15.0
accelerate==0.25.0
torch>=2.0.0
trl==0.7.4
wandb==0.16.1
scipy==1.11.4
scikit-learn==1.3.2
```

### **Estrutura de Arquivos**
```
semana06-fine-tuning/
â”œâ”€â”€ notas.md                          # Este arquivo
â”œâ”€â”€ experimentos.md                   # Suas anotaÃ§Ãµes
â”œâ”€â”€ exemplos/
â”‚   â”œâ”€â”€ exemplo_01_fine_tuning_basico.py
â”‚   â”œâ”€â”€ exemplo_02_lora_peft.py
â”‚   â”œâ”€â”€ exemplo_03_quantizacao.py
â”‚   â””â”€â”€ exemplo_04_dataset_preparation.py
â””â”€â”€ mini-projeto/
    â”œâ”€â”€ mini_projeto_fine_tuning_especializado/
    â”‚   â”œâ”€â”€ train.py                  # Script de treinamento
    â”‚   â”œâ”€â”€ inference.py              # Script de inferÃªncia
    â”‚   â”œâ”€â”€ evaluate.py               # AvaliaÃ§Ã£o de modelos
    â”‚   â”œâ”€â”€ data_prep.py              # PreparaÃ§Ã£o de dados
    â”‚   â”œâ”€â”€ app.py                    # Interface demo
    â”‚   â”œâ”€â”€ configs/                  # ConfiguraÃ§Ãµes
    â”‚   â””â”€â”€ models/                   # Modelos salvos
    â””â”€â”€ README.md
```

---

## âœ… Checklist de Aprendizado

### **Conceitos TeÃ³ricos**
- [ ] Entendo diferenÃ§as: fine-tuning vs RAG vs prompt engineering
- [ ] Compreendo matemÃ¡tica e intuiÃ§Ã£o do LoRA
- [ ] Sei quando aplicar quantizaÃ§Ã£o
- [ ] ConheÃ§o trade-offs de cada tÃ©cnica

### **Habilidades PrÃ¡ticas**
- [ ] Executei fine-tuning completo
- [ ] Implementei LoRA com PEFT
- [ ] Apliquei quantizaÃ§Ã£o 4-bit e 8-bit
- [ ] Preparei datasets personalizados
- [ ] Avaliei qualidade de modelos fine-tuned

### **Projeto Final**
- [ ] Modelo fine-tuned para caso especÃ­fico
- [ ] Pipeline de treinamento otimizado
- [ ] Interface de demonstraÃ§Ã£o
- [ ] MÃ©tricas de avaliaÃ§Ã£o implementadas
- [ ] DocumentaÃ§Ã£o tÃ©cnica completa

---

## ğŸ“ EspaÃ§o para AnotaÃ§Ãµes

### **ComparaÃ§Ã£o de TÃ©cnicas**
- **Full Fine-tuning:**
  - PrÃ³s:
  - Contras:
  - Quando usar:

- **LoRA:**
  - PrÃ³s:
  - Contras:
  - HiperparÃ¢metros Ã³timos:

### **ConfiguraÃ§Ãµes que Funcionaram**
- Rank Ã³timo:
- Alpha ideal:
- Learning rate:
- Batch size:

### **Resultados de QuantizaÃ§Ã£o**
- 8-bit: Speedup X, MemÃ³ria Y%, Qualidade Z%
- 4-bit: Speedup X, MemÃ³ria Y%, Qualidade Z%

### **LiÃ§Ãµes Aprendidas**
- (Problemas encontrados e soluÃ§Ãµes)

### **Ideias para PrÃ³ximos Projetos**
- (AplicaÃ§Ãµes de fine-tuning que poderiam explorar) 